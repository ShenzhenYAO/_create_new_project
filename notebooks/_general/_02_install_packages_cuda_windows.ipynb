{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a51b427",
   "metadata": {},
   "source": [
    "This document is about installing cuda for windows \n",
    "\n",
    "1. make venv\n",
    "cmd /c batch_files\\make_venv.bat\n",
    "\n",
    "2. upgrade pip\n",
    "cmd /c batch_files\\unrestrict_and_activate_venv_windows_py310_01.bat\n",
    "python -m pip install --upgrade pip\n",
    "\n",
    "3. Install Nvidia drive\n",
    "(I have installed it).\n",
    "\n",
    "```bash\n",
    "NVIDIA-SMI\n",
    "``` \n",
    "571.59 Driver Version: 571.59 CUDA Version: 12.8.\n",
    "\n",
    "4. Install Build Tools for Visual Studio 2022\n",
    "\n",
    "Go to `https://visualstudio.microsoft.com/vs/older-downloads/`\n",
    "Click the button Downlaod of `Visual Studio 2022 and other Products`\n",
    "Use a valid Microsoft account to log in, and from the list, download `Build Tools for Visual Studio 2022` and click the .exe file to install it.\n",
    "make sure to check and install `Desktop development with C++`, keep the default options.\n",
    "\n",
    "5. Install CUDA Toolkit for Windows\n",
    "\n",
    "Check if it is installed in a command prompt: `nvcc --version`. If it cannot be found, it is not installed.\n",
    "\n",
    "go to `https://developer.nvidia.com/cuda-toolkit-archive`, click `CUDA Toolkit 12.8.0`, which is the matched version for my NVIDIA Driver. \n",
    "click windows, x86_64, (version 11), exe (local)\n",
    "\n",
    "It will show the button Download (3.2 GB). Click to download it. \n",
    "double click to install it. It will ask to confirm to extract files to a temp folder like `C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\cuda`. \n",
    "click agree for lisence agreement, for installation options, select Custom, check all component (default). It will install in `C:\\Program Files\\NVIDIA GPU Computing ToolkitCUDA\\v12.8`.\n",
    "If it warns that some Visual Studio component is missing, go back and install `Build Tools for Visual Studio 2022`. Do not install Visual Studio 2026. it is incompatible.\n",
    "\n",
    "6. install torch cuda rutime for windows\n",
    "\n",
    "go to `https://pytorch.org/get-started/previous-versions/`, select:\n",
    "\n",
    "`pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124`\n",
    "\n",
    "\n",
    "Note: do not install cu126 or cu128, it is not compatible with P4000 and P5000\n",
    "\n",
    "Use the following to test whether the pytorch and cu126 runs fine with the GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea5da8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_path: D:\\projects\\_create_new_project\n",
      "file tyep: notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def get_project_path():\n",
    "    if \"__file__\" in globals():\n",
    "        # Running as a .py script\n",
    "        this_file_type = \"python script\"\n",
    "        project_path = Path(__file__).resolve().parent.parent.parent.parent.parent\n",
    "    else:\n",
    "        # Presume running in a Jupyter notebook; use CWDâ€™s great-grandparent\n",
    "        this_file_type = \"notebook\"\n",
    "        project_path = Path.cwd().resolve().parent.parent\n",
    "    return project_path, this_file_type\n",
    "\n",
    "project_path, this_file_type = get_project_path()\n",
    "print(\"project_path:\", project_path)\n",
    "print(\"file tyep:\", this_file_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a39a98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.9.0+cu126\n",
      "CUDA Available:  True\n",
      "CUDA Version:    12.6\n",
      "GPU Count:       2\n",
      "GPU 0:           Quadro P5000\n",
      "GPU 1:           Quadro P4000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available:  {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Version:    {torch.version.cuda}\")\n",
    "    print(f\"GPU Count:       {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU 0:           {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU 1:           {torch.cuda.get_device_name(1)}\") # Should see P4000 here\n",
    "else:\n",
    "    print(\"GPUs NOT detected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
